<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>integrators &#8212; MCintegration 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=4848ba22" />
    <link rel="stylesheet" type="text/css" href="../_static/pyramid.css?v=424f8d56" />
    <script src="../_static/documentation_options.js?v=8d563738"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="../_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head><body>

    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">MCintegration 1.0.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">integrators</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for integrators</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">RAvg</span>
<span class="kn">from</span> <span class="nn">maps</span> <span class="kn">import</span> <span class="n">Map</span><span class="p">,</span> <span class="n">Affine</span>
<span class="kn">import</span> <span class="nn">gvar</span>


<div class="viewcode-block" id="Integrator">
<a class="viewcode-back" href="../src.html#integrators.Integrator">[docs]</a>
<span class="k">class</span> <span class="nc">Integrator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for all integrators.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="c1"># bounds: Union[List[Tuple[float, float]], np.ndarray],</span>
        <span class="nb">map</span><span class="p">,</span>
        <span class="n">neval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="c1"># device=torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;),</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">Map</span><span class="p">):</span>
            <span class="nb">map</span> <span class="o">=</span> <span class="n">Affine</span><span class="p">(</span><span class="nb">map</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="nb">map</span><span class="o">.</span><span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">map</span> <span class="o">=</span> <span class="nb">map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neval</span> <span class="o">=</span> <span class="n">neval</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">neval</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">neval</span> <span class="o">=</span> <span class="n">neval</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">neval</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">neval</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Subclasses must implement this method&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="MonteCarlo">
<a class="viewcode-back" href="../src.html#integrators.MonteCarlo">[docs]</a>
<span class="k">class</span> <span class="nc">MonteCarlo</span><span class="p">(</span><span class="n">Integrator</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">map</span><span class="p">,</span>
        <span class="n">nitn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">neval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">adapt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">neval</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adapt</span> <span class="o">=</span> <span class="n">adapt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nitn</span> <span class="o">=</span> <span class="n">nitn</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">f_values</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">f_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">f_values</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f_values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">type_fval</span> <span class="o">=</span> <span class="n">f_values</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">f_size</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">type</span><span class="p">(</span><span class="n">f_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">f_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">type_fval</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">f_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">type_fval</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># var = torch.zeros((f_size, f_size), dtype=type_fval, device=self.device)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">RAvg</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">)</span>
        <span class="n">epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neval</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

        <span class="k">for</span> <span class="n">itn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nitn</span><span class="p">):</span>
            <span class="n">mean</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">var</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

                <span class="n">f_values</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">batch_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multiply_by_jacobian</span><span class="p">(</span><span class="n">f_values</span><span class="p">,</span> <span class="n">jac</span><span class="p">)</span>

                <span class="n">mean</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_results</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">epoch</span>
                <span class="n">var</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">batch_results</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neval</span> <span class="o">*</span> <span class="n">epoch</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">add_training_data</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">batch_results</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

            <span class="n">result</span><span class="o">.</span><span class="n">sum_neval</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neval</span>
            <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gvar</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="p">(</span><span class="n">var</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">_multiply_by_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">jac</span><span class="p">):</span>
        <span class="c1"># if isinstance(values, dict):</span>
        <span class="c1">#     return {k: v * torch.exp(log_det_J) for k, v in values.items()}</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">v</span> <span class="o">*</span> <span class="n">jac</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">values</span> <span class="o">*</span> <span class="n">jac</span></div>



<div class="viewcode-block" id="MCMC">
<a class="viewcode-back" href="../src.html#integrators.MCMC">[docs]</a>
<span class="k">class</span> <span class="nc">MCMC</span><span class="p">(</span><span class="n">MonteCarlo</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">map</span><span class="p">:</span> <span class="n">Map</span><span class="p">,</span>
        <span class="n">nitn</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">neval</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_burnin</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">adapt</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="nb">map</span><span class="p">,</span> <span class="n">nitn</span><span class="p">,</span> <span class="n">neval</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">adapt</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_burnin</span> <span class="o">=</span> <span class="n">n_burnin</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">f</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">proposal_dist</span><span class="o">=</span><span class="s2">&quot;global_uniform&quot;</span><span class="p">,</span>
        <span class="n">thinning</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">mix_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-16</span>  <span class="c1"># Small value to ensure numerical stability</span>
        <span class="n">vars_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">current_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vars_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">current_x</span><span class="p">,</span> <span class="n">current_jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">current_y</span><span class="p">)</span>
        <span class="n">current_fval</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">current_x</span><span class="p">)</span>
        <span class="n">current_weight</span> <span class="o">=</span> <span class="n">mix_rate</span> <span class="o">/</span> <span class="n">current_jac</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mix_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">current_fval</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
        <span class="n">current_weight</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">current_weight</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="c1"># current_fval.masked_fill_(current_fval.abs() &lt; epsilon, epsilon)</span>

        <span class="n">proposed_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">current_y</span><span class="p">)</span>
        <span class="n">proposed_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">proposed_y</span><span class="p">)</span>
        <span class="n">new_fval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">current_fval</span><span class="p">)</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">current_weight</span><span class="p">)</span>

        <span class="n">f_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_fval</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_fval</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="n">type_fval</span> <span class="o">=</span> <span class="n">current_fval</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">f_size</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">type</span><span class="p">(</span><span class="n">current_fval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">f_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">type_fval</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mean_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">f_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">type_fval</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">var_ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">RAvg</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">)</span>
        <span class="n">result_ref</span> <span class="o">=</span> <span class="n">RAvg</span><span class="p">(</span><span class="n">weighted</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">)</span>

        <span class="n">epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neval</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">n_meas</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">itn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nitn</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
                <span class="n">proposed_y</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_propose</span><span class="p">(</span><span class="n">current_y</span><span class="p">,</span> <span class="n">proposal_dist</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">proposed_x</span><span class="p">[:],</span> <span class="n">new_jac</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">proposed_y</span><span class="p">)</span>

                <span class="n">new_fval</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">proposed_x</span><span class="p">)</span>
                <span class="n">new_weight</span> <span class="o">=</span> <span class="n">mix_rate</span> <span class="o">/</span> <span class="n">new_jac</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mix_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">new_fval</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>

                <span class="n">acceptance_probs</span> <span class="o">=</span> <span class="n">new_weight</span> <span class="o">/</span> <span class="n">current_weight</span> <span class="o">*</span> <span class="n">new_jac</span> <span class="o">/</span> <span class="n">current_jac</span>

                <span class="n">accept</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="o">&lt;=</span> <span class="n">acceptance_probs</span>
                <span class="p">)</span>

                <span class="n">current_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">accept</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">proposed_y</span><span class="p">,</span> <span class="n">current_y</span><span class="p">)</span>
                <span class="n">current_fval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">accept</span><span class="p">,</span> <span class="n">new_fval</span><span class="p">,</span> <span class="n">current_fval</span><span class="p">)</span>
                <span class="n">current_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">accept</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">,</span> <span class="n">current_weight</span><span class="p">)</span>
                <span class="n">current_jac</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">accept</span><span class="p">,</span> <span class="n">new_jac</span><span class="p">,</span> <span class="n">current_jac</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_burnin</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">adapt</span> <span class="ow">or</span> <span class="n">itn</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">i</span> <span class="o">%</span> <span class="n">thinning</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">n_meas</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">batch_results</span> <span class="o">=</span> <span class="n">current_fval</span> <span class="o">/</span> <span class="n">current_weight</span>

                    <span class="n">mean</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_results</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">epoch</span>
                    <span class="n">var</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">batch_results</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">epoch</span>

                    <span class="n">batch_results_ref</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">current_jac</span> <span class="o">*</span> <span class="n">current_weight</span><span class="p">)</span>
                    <span class="n">mean_ref</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_results_ref</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">epoch</span>
                    <span class="n">var_ref</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">batch_results_ref</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">epoch</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">add_training_data</span><span class="p">(</span>
                            <span class="n">current_y</span><span class="p">,</span> <span class="p">(</span><span class="n">current_fval</span> <span class="o">*</span> <span class="n">current_jac</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
                        <span class="p">)</span>
            <span class="n">result</span><span class="o">.</span><span class="n">sum_neval</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neval</span>
            <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gvar</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="p">((</span><span class="n">var</span> <span class="o">/</span> <span class="n">n_meas</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
            <span class="n">result_ref</span><span class="o">.</span><span class="n">sum_neval</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">result_ref</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">gvar</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">mean_ref</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="p">((</span><span class="n">var_ref</span> <span class="o">/</span> <span class="n">n_meas</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">map</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span> <span class="o">/</span> <span class="n">result_ref</span>

    <span class="k">def</span> <span class="nf">_propose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">proposal_dist</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">proposal_dist</span> <span class="o">==</span> <span class="s2">&quot;random_walk&quot;</span><span class="p">:</span>
            <span class="n">step_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;step_size&quot;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">)</span> <span class="o">%</span> <span class="mf">1.0</span>
        <span class="k">elif</span> <span class="n">proposal_dist</span> <span class="o">==</span> <span class="s2">&quot;global_uniform&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="c1"># elif proposal_dist == &quot;gaussian&quot;:</span>
        <span class="c1">#     mean = kwargs.get(&quot;mean&quot;, torch.zeros_like(u))</span>
        <span class="c1">#     std = kwargs.get(&quot;std&quot;, torch.ones_like(u))</span>
        <span class="c1">#     return torch.normal(mean, std)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown proposal distribution: </span><span class="si">{</span><span class="n">proposal_dist</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">MCintegration 1.0.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">integrators</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2024, Authors.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    </div>
  </body>
</html>